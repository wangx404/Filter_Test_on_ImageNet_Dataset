# 背景介绍

通常情况下，我们用来训练DCNN模型的图像都是三通道的RGB图像；在少数情况下，我们也有可能使用单通道的灰度图像。然而不管是哪一种图像，像素的取值范围都是0-255(即8bit），可我们真得需要8bit的数据吗？在mnist这样的数据集中，图像由0和1两种像素值组成，然而我们（人类）仍然能够分辨出其中的信息。所以如果我们对RGB图像进行类似的处理（减少图像的bit位数），图像的信息会丢失多少？DCNN模型的准确率会发生什么变化呢？本文所进行的尝试就是基于此想法进行的。

# 图像过滤处理

此处所谓的图像过滤处理即压缩图像的bit位数，其处理过程可以用公式`v = v//(2**n)*(2**n)`来表示。公式中的`v`为像素值，`n`为过滤的级别（1-7）。假如某一像素的数值为255，经过1-7级别的过滤处理后，其数值变为了254,252,248,240,224,192,128。你也可以将此过程视为，将像素值低bit位逐步置为0的过程。

从下图中可以看出，随着过滤级别的逐渐增加（从左到右，从上到下，过滤级别依次为0-7），图像丢失了越来越多的细节信息（主要是纹理信息），但是我们仍然可以分辨出图像主体是两只狗狗。那么对于在ImageNet上进行训练的DCNN模型来说，它们还能做出正确的预测吗？

[!dog](dog.jpg)

# 试验过程

1.	下载ImageNet的验证集并对其重新整理，以便能够MXNet的数据集加载函数可以正常工作。具体代码参照`sort_imagenet_dataset.py`。
2.	使用MXNet中的预训练模型对其进行测试。具体代码参照`filter_test.py`。

# 试验结果

经过图像过滤处理后，ResNet34_v2在ImageNet上的准确率如下表所示。（根据MXNet的官方文档可知，此模型的Top-1准确率为0.7440，Top-5准确率为0.9208。）

| Filter Level | Top-1 Accuracy | Top-5 Accuracy |
| :----:| :----: | :----: |
| 0 | 0.739 | 0.918 |
| 1 | 0.739 | 0.918 |
| 2 | 0.739 | 0.918 |
| 3 | 0.738 | 0.918 |
| 4 | 0.732 | 0.914 |
| 5 | 0.707 | 0.899 |
| 6 | 0.619 | 0.837 |
| 7 | 0.362 | 0.590 |

在过滤级别小于等于4时，预训练模型仍然具有较高的准确性（非常接近官方数值）；之后，随着过滤级别增大，准确率逐渐下降；在过滤级别等于7时，模型的准确率已经非常低了。

# 结果讨论

某些论文（例如ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness）的结果已经表明DCNN模型在进行类别预测时更倾向于使用图像的纹理信息。我们的试验结果可以部分证实这一点（图像纹理信息严重损失时模型的准确率严重下降）。但同时我们还可以看出，基于原始图像训练的模型对于损失了部分纹理信息的图像仍然有很高的准确性。

# 可能的用途

1.	增加模型的稳健性

DCNN面临的一个严重问题是，面对对抗样本时的脆弱性。FGSM和C&W等方法可以通过修改图像的像素值来改变图像的预测值。而且，这些像素值的修改往往是肉眼不可见的。从相关代码中我们可以看出，攻击方法对像素值的修改幅度非常小。这也就意味着如果我们能够使用某种方法将添加的数值过滤掉，我们就可以增加模型的抗攻击能力。对图像进行过滤处理可能是一个可行的思路。假如攻击模型对像素值修改的delta为1，而我们的过滤等级为3，这时某一段像素值的变化如下所示：

| Origin | Filter on origin image | Add noise | Filter on noised image |
| :----:| :----: | :----: | :----: |
| 0 | 0 | 1 | 0 |
| 1 | 0 | 2 | 0 |
| 2 | 0 | 3 | 0 |
| 3 | 0 | 4 | 0 |
| 4 | 0 | 5 | 0 |
| 5 | 0 | 6 | 0 |
| 6 | 0 | 7 | 0 |
| 7 | 0 | 8 | 1 |
| 8 | 1 | 8 | 1 |

从上表可以看出，和在原始图像上进行过滤的结果相比，经过添加噪音+过滤处理后，结果几乎没有变化（7的数值+1后越过了`2**3=8`的界限，所以结果发生了变化）。受影响的像素值占全部像素的比例为 `delta/(2**n)`，和过滤处理前相比，此数值大大降低。同时，由于这一级别的过滤处理对模型的准确性影响很小，因此模型抵抗对抗样本的能力得到了增强。

另外，从数据分布的角度看，对低bit位数值进行过滤了，现有的数据分布边界被约束到了一个更小的范围内。以一张100*100的灰度图像为例，8bit时可能的图像数目为`256**(100*100)`,即`2**80000`。但是4bit时可能的图像数目就减少为`64**(100*100)`,即`2**40000`。数据分布空间越简单，也就意味着训练得到的模型的稳健性可能越好。

2.	低精度训练

既然数据精度（bit位数减少）的降低对模型的性能影响较小，是不是我们完全可以放弃使用float32进行训练，转为使用更低的数据精度？（如果不会出现数据下溢的问题）

# 后续延伸

如果进一步进行试验，我们还可以使用经过了图像过滤处理的ImageNet数据集进行模型的训练和验证。此时模型的准确率会发生什么样的变化呢？

按照上述的思路在小型数据集上（例如包含了2w张训练图像的猫狗数据集）进行训练，得到的结果是类似的。即，使用过滤处理的图像对DCNN模型进行训练后，模型的准确率会有轻微下降。只有在过滤级别达到了6/7时，模型的准确率才会严重下降。

如果你有足够的显卡和时间，也可以在ImageNet上进行验证。我想结果可能是类似的。
